#!/usr/bin/env python3
"""
Frontend End-to-End Test Suite
Comprehensive testing of GUI components and backend integration
"""

import os
import sys
import json
import time
import subprocess
import asyncio
from pathlib import Path
from datetime import datetime
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('frontend_e2e_test.log', mode='w'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('FRONTEND_E2E')

class FrontendE2ETest:
    """Comprehensive frontend testing suite"""
    
    def __init__(self):
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'components': {},
            'integration': {},
            'api_calls': {},
            'ui_elements': {},
            'errors': []
        }
        self.frontend_dir = Path("usenet-sync-app")
        self.tauri_dir = self.frontend_dir / "src-tauri"
        
    async def run_all_tests(self):
        """Run complete frontend test suite"""
        logger.info("="*80)
        logger.info("ğŸ¨ FRONTEND END-TO-END TEST SUITE")
        logger.info("="*80)
        
        total_tests = 0
        passed_tests = 0
        
        # Phase 1: Environment Setup
        logger.info("\nğŸ“¦ PHASE 1: ENVIRONMENT SETUP")
        logger.info("-"*60)
        
        # Check Node.js and npm
        logger.info("Checking Node.js environment...")
        total_tests += 1
        if self._check_node_environment():
            passed_tests += 1
            self.results['components']['node_env'] = 'PASSED'
        else:
            self.results['components']['node_env'] = 'FAILED'
        
        # Install dependencies
        logger.info("Checking npm dependencies...")
        total_tests += 1
        if self._check_npm_dependencies():
            passed_tests += 1
            self.results['components']['npm_deps'] = 'PASSED'
        else:
            self.results['components']['npm_deps'] = 'FAILED'
        
        # Phase 2: Component Testing
        logger.info("\nğŸ§© PHASE 2: REACT COMPONENT TESTING")
        logger.info("-"*60)
        
        # Test each component
        components_to_test = [
            'AppShell', 'FileTree', 'SearchBar', 'ConnectionStatus',
            'LicenseActivation', 'StatusBar', 'HeaderBar', 'NotificationCenter',
            'FileGridView', 'BreadcrumbNav', 'BatchOperations', 'ContextMenu',
            'VersionHistory', 'ProgressIndicator', 'QRCodeDisplay'
        ]
        
        for component in components_to_test:
            total_tests += 1
            if self._test_component(component):
                passed_tests += 1
                self.results['components'][component] = 'PASSED'
                logger.info(f"  âœ… {component}")
            else:
                self.results['components'][component] = 'FAILED'
                logger.error(f"  âŒ {component}")
        
        # Phase 3: Page Testing
        logger.info("\nğŸ“„ PHASE 3: PAGE TESTING")
        logger.info("-"*60)
        
        pages_to_test = [
            'Upload', 'Download', 'Shares', 'Settings', 'Logs', 'TestRunner'
        ]
        
        for page in pages_to_test:
            total_tests += 1
            if self._test_page(page):
                passed_tests += 1
                self.results['components'][f'Page_{page}'] = 'PASSED'
                logger.info(f"  âœ… {page} page")
            else:
                self.results['components'][f'Page_{page}'] = 'FAILED'
                logger.error(f"  âŒ {page} page")
        
        # Phase 4: Tauri Integration
        logger.info("\nğŸ¦€ PHASE 4: TAURI INTEGRATION")
        logger.info("-"*60)
        
        # Test Tauri commands
        tauri_commands = [
            'get_system_info', 'get_logs', 'set_bandwidth_limit',
            'get_bandwidth_stats', 'export_data', 'import_data',
            'clear_cache', 'restart_services', 'get_statistics'
        ]
        
        for command in tauri_commands:
            total_tests += 1
            if self._test_tauri_command(command):
                passed_tests += 1
                self.results['integration'][command] = 'PASSED'
                logger.info(f"  âœ… {command}")
            else:
                self.results['integration'][command] = 'FAILED'
                logger.error(f"  âŒ {command}")
        
        # Phase 5: Backend API Integration
        logger.info("\nğŸ”Œ PHASE 5: BACKEND API INTEGRATION")
        logger.info("-"*60)
        
        # Test API endpoints
        api_endpoints = [
            'upload_file', 'download_file', 'create_share', 
            'get_shares', 'delete_share', 'get_settings',
            'update_settings', 'get_server_status'
        ]
        
        for endpoint in api_endpoints:
            total_tests += 1
            if self._test_api_endpoint(endpoint):
                passed_tests += 1
                self.results['api_calls'][endpoint] = 'PASSED'
                logger.info(f"  âœ… {endpoint}")
            else:
                self.results['api_calls'][endpoint] = 'FAILED'
                logger.error(f"  âŒ {endpoint}")
        
        # Phase 6: UI Elements
        logger.info("\nğŸ¯ PHASE 6: UI ELEMENTS")
        logger.info("-"*60)
        
        # Test UI elements
        ui_elements = [
            'drag_drop', 'keyboard_shortcuts', 'context_menus',
            'notifications', 'modals', 'tooltips', 'forms',
            'tables', 'charts', 'progress_bars'
        ]
        
        for element in ui_elements:
            total_tests += 1
            if self._test_ui_element(element):
                passed_tests += 1
                self.results['ui_elements'][element] = 'PASSED'
                logger.info(f"  âœ… {element}")
            else:
                self.results['ui_elements'][element] = 'FAILED'
                logger.error(f"  âŒ {element}")
        
        # Phase 7: Build and Bundle
        logger.info("\nğŸ“¦ PHASE 7: BUILD AND BUNDLE")
        logger.info("-"*60)
        
        # Test production build
        total_tests += 1
        if self._test_production_build():
            passed_tests += 1
            self.results['integration']['production_build'] = 'PASSED'
            logger.info("  âœ… Production build successful")
        else:
            self.results['integration']['production_build'] = 'FAILED'
            logger.error("  âŒ Production build failed")
        
        # Calculate results
        self.results['summary'] = {
            'total_tests': total_tests,
            'passed': passed_tests,
            'failed': total_tests - passed_tests,
            'pass_rate': (passed_tests / total_tests * 100) if total_tests > 0 else 0
        }
        
        return self.results
    
    def _check_node_environment(self) -> bool:
        """Check Node.js and npm are installed"""
        try:
            # Check Node.js
            result = subprocess.run(['node', '--version'], capture_output=True)
            if result.returncode != 0:
                return False
            
            # Check npm
            result = subprocess.run(['npm', '--version'], capture_output=True)
            if result.returncode != 0:
                return False
            
            return True
        except:
            return False
    
    def _check_npm_dependencies(self) -> bool:
        """Check npm dependencies are installed"""
        try:
            # Check if node_modules exists
            node_modules = self.frontend_dir / "node_modules"
            if not node_modules.exists():
                # Install dependencies
                logger.info("Installing npm dependencies...")
                result = subprocess.run(
                    ['npm', 'install'],
                    cwd=self.frontend_dir,
                    capture_output=True,
                    timeout=120
                )
                if result.returncode != 0:
                    return False
            
            return True
        except:
            return False
    
    def _test_component(self, component_name: str) -> bool:
        """Test a React component exists and exports correctly"""
        try:
            component_file = self.frontend_dir / "src" / "components" / f"{component_name}.tsx"
            if not component_file.exists():
                return False
            
            # Check component exports
            with open(component_file, 'r') as f:
                content = f.read()
                
            # Check for proper export
            if f'export default {component_name}' in content or f'export {{ {component_name} }}' in content:
                return True
            
            return 'export' in content and component_name in content
            
        except:
            return False
    
    def _test_page(self, page_name: str) -> bool:
        """Test a page component exists"""
        try:
            page_file = self.frontend_dir / "src" / "pages" / f"{page_name}.tsx"
            if not page_file.exists():
                return False
            
            # Check page structure
            with open(page_file, 'r') as f:
                content = f.read()
            
            # Check for React component structure
            return 'return' in content and ('jsx' in content or '<' in content)
            
        except:
            return False
    
    def _test_tauri_command(self, command_name: str) -> bool:
        """Test a Tauri command is defined"""
        try:
            # Check TypeScript bindings
            tauri_file = self.frontend_dir / "src" / "lib" / "tauri.ts"
            if tauri_file.exists():
                with open(tauri_file, 'r') as f:
                    content = f.read()
                if command_name in content:
                    return True
            
            # Check Rust implementation
            rust_files = list(self.tauri_dir.glob("src/**/*.rs"))
            for rust_file in rust_files:
                with open(rust_file, 'r') as f:
                    content = f.read()
                if f'#[tauri::command]' in content and command_name in content:
                    return True
            
            return False
            
        except:
            return False
    
    def _test_api_endpoint(self, endpoint_name: str) -> bool:
        """Test an API endpoint is integrated"""
        try:
            # Check for API calls in TypeScript
            api_file = self.frontend_dir / "src" / "lib" / "api.ts"
            if api_file.exists():
                with open(api_file, 'r') as f:
                    content = f.read()
                if endpoint_name in content:
                    return True
            
            # Check in Tauri bindings
            tauri_file = self.frontend_dir / "src" / "lib" / "tauri.ts"
            if tauri_file.exists():
                with open(tauri_file, 'r') as f:
                    content = f.read()
                if endpoint_name in content:
                    return True
            
            # Check in pages/components
            src_dir = self.frontend_dir / "src"
            for ts_file in src_dir.rglob("*.tsx"):
                with open(ts_file, 'r') as f:
                    content = f.read()
                if endpoint_name in content:
                    return True
            
            return False
            
        except:
            return False
    
    def _test_ui_element(self, element_name: str) -> bool:
        """Test UI element implementation"""
        try:
            # Map element names to code patterns
            element_patterns = {
                'drag_drop': 'useDragDrop',
                'keyboard_shortcuts': 'useKeyboardShortcuts',
                'context_menus': 'ContextMenu',
                'notifications': 'NotificationCenter',
                'modals': 'Dialog',
                'tooltips': 'Tooltip',
                'forms': 'useForm',
                'tables': 'Table',
                'charts': 'Chart',
                'progress_bars': 'Progress'
            }
            
            pattern = element_patterns.get(element_name, element_name)
            
            # Search for pattern in components
            src_dir = self.frontend_dir / "src"
            for tsx_file in src_dir.rglob("*.tsx"):
                with open(tsx_file, 'r') as f:
                    content = f.read()
                if pattern in content:
                    return True
            
            return False
            
        except:
            return False
    
    def _test_production_build(self) -> bool:
        """Test production build"""
        try:
            logger.info("Running production build...")
            
            # Build frontend
            result = subprocess.run(
                ['npm', 'run', 'build'],
                cwd=self.frontend_dir,
                capture_output=True,
                timeout=120
            )
            
            if result.returncode != 0:
                logger.error(f"Build failed: {result.stderr.decode()[:200]}")
                return False
            
            # Check build output
            dist_dir = self.frontend_dir / "dist"
            if not dist_dir.exists():
                return False
            
            # Check for required files
            index_html = dist_dir / "index.html"
            if not index_html.exists():
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Build test failed: {e}")
            return False
    
    def generate_report(self):
        """Generate comprehensive test report"""
        report = []
        report.append("="*80)
        report.append("ğŸ¨ FRONTEND E2E TEST REPORT")
        report.append("="*80)
        report.append(f"Timestamp: {self.results['timestamp']}")
        report.append("")
        
        # Component results
        report.append("ğŸ“¦ REACT COMPONENTS:")
        report.append("-"*60)
        for name, status in self.results['components'].items():
            icon = "âœ…" if status == "PASSED" else "âŒ"
            report.append(f"  {icon} {name}: {status}")
        
        # Integration results
        report.append("")
        report.append("ğŸ”Œ INTEGRATION:")
        report.append("-"*60)
        for name, status in self.results['integration'].items():
            icon = "âœ…" if status == "PASSED" else "âŒ"
            report.append(f"  {icon} {name}: {status}")
        
        # API results
        report.append("")
        report.append("ğŸŒ API ENDPOINTS:")
        report.append("-"*60)
        for name, status in self.results['api_calls'].items():
            icon = "âœ…" if status == "PASSED" else "âŒ"
            report.append(f"  {icon} {name}: {status}")
        
        # UI Elements
        report.append("")
        report.append("ğŸ¯ UI ELEMENTS:")
        report.append("-"*60)
        for name, status in self.results['ui_elements'].items():
            icon = "âœ…" if status == "PASSED" else "âŒ"
            report.append(f"  {icon} {name}: {status}")
        
        # Summary
        summary = self.results.get('summary', {})
        report.append("")
        report.append("="*80)
        report.append("ğŸ“Š SUMMARY:")
        report.append("-"*60)
        report.append(f"Total Tests: {summary.get('total_tests', 0)}")
        report.append(f"Passed: {summary.get('passed', 0)} âœ…")
        report.append(f"Failed: {summary.get('failed', 0)} âŒ")
        report.append(f"Pass Rate: {summary.get('pass_rate', 0):.1f}%")
        
        if summary.get('pass_rate', 0) == 100:
            report.append("")
            report.append("ğŸ‰ FRONTEND 100% FUNCTIONAL!")
            report.append("All components and integrations working perfectly.")
        elif summary.get('pass_rate', 0) >= 90:
            report.append("")
            report.append("âœ… FRONTEND MOSTLY FUNCTIONAL")
            report.append("Minor issues to address.")
        else:
            report.append("")
            report.append("âš ï¸ FRONTEND NEEDS ATTENTION")
            report.append("Several components need fixes.")
        
        report.append("="*80)
        
        return "\n".join(report)

async def main():
    """Run frontend E2E tests"""
    tester = FrontendE2ETest()
    
    try:
        # Run tests
        results = await tester.run_all_tests()
        
        # Generate report
        report = tester.generate_report()
        print("\n" + report)
        
        # Save report
        report_file = Path("frontend_e2e_report.txt")
        report_file.write_text(report)
        logger.info(f"\nğŸ“„ Report saved to {report_file}")
        
        # Save JSON results
        json_file = Path("frontend_e2e_results.json")
        json_file.write_text(json.dumps(results, indent=2, default=str))
        logger.info(f"ğŸ“„ JSON results saved to {json_file}")
        
        # Return status
        if results['summary']['pass_rate'] == 100:
            logger.info("\nğŸ‰ Frontend 100% functional!")
            return 0
        else:
            logger.info(f"\nâš ï¸ Frontend {results['summary']['pass_rate']:.1f}% functional")
            return 1
            
    except Exception as e:
        logger.error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)